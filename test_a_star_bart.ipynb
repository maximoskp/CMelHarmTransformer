{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d4903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/media/maindisk/maximos/repos/CMelHarmTransformer/a_star.py:27: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  or '<\\m>' in tokens[i]:\n"
     ]
    }
   ],
   "source": [
    "from harmony_tokenizers_m21 import ChordSymbolTokenizer, PitchClassTokenizer, MelodyPitchTokenizer, MergedMelHarmTokenizer\n",
    "from data_utils import StructBARTMelHarmDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartConfig, DataCollatorForSeq2Seq\n",
    "import numpy as np\n",
    "\n",
    "from a_star import AStarBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20b01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/media/maindisk/maximos/data/hooktheory_test'\n",
    "\n",
    "cstok = ChordSymbolTokenizer()\n",
    "pctok = PitchClassTokenizer()\n",
    "meltok = MelodyPitchTokenizer()\n",
    "tokenizer = MergedMelHarmTokenizer(meltok, cstok)\n",
    "# tokenizer = MergedMelHarmTokenizer(meltok, pctok)\n",
    "\n",
    "test_dataset = StructBARTMelHarmDataset(test_dir, tokenizer, max_length=512, num_bars=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d19a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(547, 512, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(547, 512, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(514, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(547, 512, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(514, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=547, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_config = BartConfig(\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=tokenizer.bos_token_id,\n",
    "    forced_eos_token_id=tokenizer.eos_token_id,\n",
    "    max_position_embeddings=512,\n",
    "    encoder_layers=8,\n",
    "    encoder_attention_heads=8,\n",
    "    encoder_ffn_dim=512,\n",
    "    decoder_layers=8,\n",
    "    decoder_attention_heads=8,\n",
    "    decoder_ffn_dim=512,\n",
    "    d_model=512,\n",
    "    encoder_layerdrop=0.25,\n",
    "    decoder_layerdrop=0.25,\n",
    "    dropout=0.25\n",
    ")\n",
    "\n",
    "model = BartForConditionalGeneration(bart_config)\n",
    "\n",
    "model_path = 'saved_models/bart/ChordSymbolTokenizer/ChordSymbolTokenizer.pt'\n",
    "# model_path = 'saved_models/bart/PitchClassTokenizer/PitchClassTokenizer.pt'\n",
    "\n",
    "# device_name = 'cuda:0'\n",
    "device_name = 'cpu'\n",
    "if device_name == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(device_name)\n",
    "    else:\n",
    "        print('Selected device not available: ' + device_name)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device_name, weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cdf369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_collator(tokenizer, model):\n",
    "    return DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "\n",
    "collator = create_data_collator(tokenizer, model=model)\n",
    "\n",
    "trainloader = DataLoader(test_dataset, batch_size=1, shuffle=True, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ec48da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n",
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec63bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  2,   6, 183,  98,  58, 106,  61, 114,  61, 122,  58, 126,  56,   6,\n",
      "          98,  58, 106,  61, 114,  61, 122,  58, 126,  56,   6,  98,  58, 106,\n",
      "          63, 114,  63, 122,  58, 126,  56,   6,  98,  58, 106,  63, 114,  63,\n",
      "         122,   4, 126,  58, 128,  58,   6,  98,  61, 106,  65, 114,  65, 122,\n",
      "          63, 126,  61,   6,  98,  61, 106,  65, 114,  65, 122,  63, 126,  65,\n",
      "           6,  98,  66, 114,  61,   6,  98,  57, 114,   4, 122,  61, 126,  63,\n",
      "           8,   6,   9,   6,   9,   6,   9,   6,   9,   6,   9,   6,   9,   6,\n",
      "          98, 355,   9,   6,   9,   3]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  7,   6,  98, 461,   6,  98, 461,   6,  98, 402,   6,  98, 402,   6,\n",
      "          98, 199,   6,  98, 199,   6,  98, 355,   6,  98, 355,   3]]), 'decoder_input_ids': tensor([[  2,   7,   6,  98, 461,   6,  98, 461,   6,  98, 402,   6,  98, 402,\n",
      "           6,  98, 199,   6,  98, 199,   6,  98, 355,   6,  98, 355]])}\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2586d77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   6, 183,  98,  58, 106,  61, 114,  61, 122,  58, 126,  56,   6,\n",
      "          98,  58, 106,  61, 114,  61, 122,  58, 126,  56,   6,  98,  58, 106,\n",
      "          63, 114,  63, 122,  58, 126,  56,   6,  98,  58, 106,  63, 114,  63,\n",
      "         122,   4, 126,  58, 128,  58,   6,  98,  61, 106,  65, 114,  65, 122,\n",
      "          63, 126,  61,   6,  98,  61, 106,  65, 114,  65, 122,  63, 126,  65,\n",
      "           6,  98,  66, 114,  61,   6,  98,  57, 114,   4, 122,  61, 126,  63,\n",
      "           8,   6,   9,   6,   9,   6,   9,   6,   9,   6,   9,   6,   9,   6,\n",
      "          98, 355,   9,   6,   9,   3]])\n",
      "84\n",
      "tensor([  8,   6,   9,   6,   9,   6,   9,   6,   9,   6,   9,   6,   9,   6,\n",
      "         98, 355,   9,   6,   9,   3])\n",
      "torch.Size([1, 104])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "all_ids = batch['input_ids']\n",
    "print(all_ids)\n",
    "melody_end_index = all_ids[0].tolist().index( tokenizer.vocab['</m>'] )\n",
    "print(melody_end_index)\n",
    "constraint_ids = all_ids[0][melody_end_index:]\n",
    "print(constraint_ids)\n",
    "# start_harmony_position = np.where( all_ids == harmony_start_index )[0][0]\n",
    "input_ids = all_ids.clone()\n",
    "print(input_ids.shape)\n",
    "print(tokenizer.vocab['</s>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5513f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "astar = AStarBART( model, tokenizer, input_ids, constraint_ids, max_length=512, beam_width=20, lookahead_k=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5c8ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "position_0x00\n",
      "['F:min6']\n"
     ]
    }
   ],
   "source": [
    "print(astar.constraint_bar)\n",
    "print(astar.position_token)\n",
    "print(astar.chord_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8760519",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids, model_calls = astar.decode()\n",
    "generated_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e23d1b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 17])\n"
     ]
    }
   ],
   "source": [
    "print(generated_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f181c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "print(model_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e23e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<h>', '<bar>', '<bar>', '<bar>', '<bar>', '<bar>', 'position_0x00', 'C:maj', '<bar>', '<bar>', 'position_0x00', 'F:min6', '<bar>', 'position_0x00', 'F:min6', '</s>']\n"
     ]
    }
   ],
   "source": [
    "for i in generated_ids[0]:\n",
    "    generated_tokens.append( tokenizer.ids_to_tokens[ int(i) ].replace(' ','x') )\n",
    "print(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1c371cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<h>']\n",
      "['<bar>']\n",
      "['<bar>']\n",
      "['<bar>']\n",
      "['<bar>']\n",
      "['<bar>', 'position_0x00', 'C:maj']\n",
      "['<bar>']\n",
      "['<bar>', 'position_0x00', 'F:min6']\n",
      "['<bar>', 'position_0x00', 'F:min6', '</s>']\n"
     ]
    }
   ],
   "source": [
    "t = generated_tokens\n",
    "line = []\n",
    "for i in range(len(t)):\n",
    "    line.append(t[i])\n",
    "    if i+1 < len(t) and 'bar' in t[i+1]:\n",
    "        print(line)\n",
    "        line = []\n",
    "print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
